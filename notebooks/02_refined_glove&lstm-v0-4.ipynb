{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb6b815",
   "metadata": {},
   "source": [
    "\n",
    "# Sentiment Analysis — Refined \n",
    "This notebook contains a cleaned, fixed, and robust pipeline for Twitter sentiment analysis using an LSTM-based model.\n",
    "\n",
    "**What was fixed & added**\n",
    "- Tokenizer vocabulary increased to 10,000\n",
    "- Negations preserved in stopword removal (`no`, `not`, `nor`)\n",
    "- Stemming and lemmatization functions corrected\n",
    "- Consistent preprocessing for training and inference\n",
    "- Optional GloVe Twitter embeddings loader (falls back to random embeddings if missing)\n",
    "- Bidirectional LSTM model with early stopping\n",
    "- Train/test split, model saving, tokenizer saving\n",
    "- `ModelWrapper` class for inference with neutral band and VADER fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d70b650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:06:48.836119Z",
     "iopub.status.busy": "2025-10-24T08:06:48.835598Z",
     "iopub.status.idle": "2025-10-24T08:07:11.671055Z",
     "shell.execute_reply": "2025-10-24T08:07:11.670265Z",
     "shell.execute_reply.started": "2025-10-24T08:06:48.836086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "2025-10-24 08:06:54.087835: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761293214.508639      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761293214.633644      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports and environment setup\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  \n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Embedding, Bidirectional\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "print('Imports done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f045e0db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:07:11.672877Z",
     "iopub.status.busy": "2025-10-24T08:07:11.672416Z",
     "iopub.status.idle": "2025-10-24T08:07:24.807386Z",
     "shell.execute_reply": "2025-10-24T08:07:24.806625Z",
     "shell.execute_reply.started": "2025-10-24T08:07:11.672856Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with shape: (1600000, 6)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/kaggle/input/sentiment/training.1600000.processed.noemoticon.csv\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    print(\"Warning: default dataset path not found:\", DATA_PATH)\n",
    "    print(\"Please update DATA_PATH to where you placed the CSV file.\")\n",
    "else:\n",
    "    data = pd.read_csv(DATA_PATH, encoding=\"ISO-8859-1\", engine=\"python\", header=None)\n",
    "    data = data.iloc[:, :6]\n",
    "    data.columns = [\"label\", \"id\", \"date\", \"query\", \"username\", \"text\"]\n",
    "    print(\"Loaded dataset with shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363033f-9eaf-40d7-b752-332057052aa4",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# SECTION 1: Data Preprocessing\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a381ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:07:24.808371Z",
     "iopub.status.busy": "2025-10-24T08:07:24.808102Z",
     "iopub.status.idle": "2025-10-24T08:07:24.823385Z",
     "shell.execute_reply": "2025-10-24T08:07:24.822744Z",
     "shell.execute_reply.started": "2025-10-24T08:07:24.808353Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing functions ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "STOPWORDS = set(stopwords.words('english')) - {\"no\", \"not\", \"nor\"}\n",
    "\n",
    "tokenizer_re = RegexpTokenizer(r'\\w+')\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove URLs and emails\n",
    "    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', text)\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', ' ', text)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # remove punctuation\n",
    "    \n",
    "    text = re.sub(r'\\d+', ' ', text)  # remove numbers\n",
    "    \n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)  # reduce repeated chars\n",
    "    \n",
    "    tokens = tokenizer_re.tokenize(text)\n",
    "    \n",
    "    # remove stopwords but keep negations \n",
    "    tokens = [t for t in tokens if t not in STOPWORDS]\n",
    "    \n",
    "    # lemmatize \n",
    "    tokens = [wnl.lemmatize(t) for t in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "print('Preprocessing functions ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "259a90b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:07:24.824809Z",
     "iopub.status.busy": "2025-10-24T08:07:24.824253Z",
     "iopub.status.idle": "2025-10-24T08:07:37.905469Z",
     "shell.execute_reply": "2025-10-24T08:07:37.904673Z",
     "shell.execute_reply.started": "2025-10-24T08:07:24.824788Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset prepared, shape = (200000, 2)\n",
      "After cleaning (removed empty), shape = (199088, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare a manageable subset (configurable)\n",
    "try:\n",
    "    data  \n",
    "except NameError:\n",
    "    raise RuntimeError(\"Dataset not loaded. Please set DATA_PATH correctly and run the load cell.\")\n",
    "\n",
    "# Keep only needed columns\n",
    "data = data[['text', 'label']].copy()\n",
    "data['label'] = data['label'].map({0:0, 4:1})\n",
    "\n",
    "# Take a subset to fit in memory.(adjust)\n",
    "POS_SAMPLES = 100000 \n",
    "NEG_SAMPLES = 100000 \n",
    "pos = data[data['label']==1].sample(frac=1, random_state=42)\n",
    "neg = data[data['label']==0].sample(frac=1, random_state=42)\n",
    "\n",
    "pos = pos.iloc[:POS_SAMPLES]\n",
    "neg = neg.iloc[:NEG_SAMPLES]\n",
    "data = pd.concat([pos, neg]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print('Subset prepared, shape =', data.shape)\n",
    "\n",
    "# Clean the text column \n",
    "data['clean_text'] = data['text'].apply(clean_text)\n",
    "data = data[data['clean_text'].str.strip().astype(bool)].reset_index(drop=True)\n",
    "print('After cleaning (removed empty), shape =', data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52d221a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:07:37.908117Z",
     "iopub.status.busy": "2025-10-24T08:07:37.907559Z",
     "iopub.status.idle": "2025-10-24T08:07:42.071709Z",
     "shell.execute_reply": "2025-10-24T08:07:42.070721Z",
     "shell.execute_reply.started": "2025-10-24T08:07:37.908096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer fit. Vocab size (len tok.word_index) = 67509\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenizer and sequences\n",
    "MAX_LEN = 50  \n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "tok = Tokenizer(num_words=VOCAB_SIZE, oov_token='<UNK>')\n",
    "tok.fit_on_texts(data['clean_text'].values)\n",
    "sequences = tok.texts_to_sequences(data['clean_text'].values)\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen=MAX_LEN)\n",
    "\n",
    "# Save tokenizer for later use\n",
    "with open('/kaggle/working/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Tokenizer fit. Vocab size (len tok.word_index) =', len(tok.word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9436a0-1170-4ca4-9dab-15c1ce18eaeb",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# SECTION 2: Preparation for model training and Glove\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# GloVe (Global Vectors for Word Representation)  is a pre-trained word embedding model created by \n",
    "# Stanford, trained on billions of tokens (Twitter, Wikipedia, etc.).\n",
    "\n",
    "# Each word is represented as a vector of real numbers (like a coordinate in a 100-dimensional space), \n",
    "# where semantically similar words are close together.\n",
    "\n",
    "# vec(\"happy\") ≈ vec(\"joyful\")\n",
    "# vec(\"sad\") ≈ vec(\"unhappy\")\n",
    "# vec(\"king\") - vec(\"man\") + vec(\"woman\") ≈ vec(\"queen\")\n",
    "\n",
    "# Without GloVe, semantic understanding of model is poor (model must learn from scratch)\n",
    "# With GloVe, it becomes excellent as the model already “knows” word relationships. \n",
    "# It also works well even with smaller subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c614d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:07:42.072916Z",
     "iopub.status.busy": "2025-10-24T08:07:42.072605Z",
     "iopub.status.idle": "2025-10-24T08:07:42.162979Z",
     "shell.execute_reply": "2025-10-24T08:07:42.162218Z",
     "shell.execute_reply.started": "2025-10-24T08:07:42.072874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (159270, 50) Test shape: (39818, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train/test split\n",
    "X = sequences_matrix\n",
    "y = data['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0805c2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:07:42.164023Z",
     "iopub.status.busy": "2025-10-24T08:07:42.163701Z",
     "iopub.status.idle": "2025-10-24T08:08:14.411540Z",
     "shell.execute_reply": "2025-10-24T08:08:14.410795Z",
     "shell.execute_reply.started": "2025-10-24T08:07:42.164003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GloVe file at /kaggle/input/glove-twitter/glove.twitter.27B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load GloVe Twitter embeddings \n",
    "EMBEDDING_DIM = 100\n",
    "embedding_matrix = None\n",
    "\n",
    "glove_paths = [\n",
    "    '/kaggle/input/glove-twitter/glove.twitter.27B.100d.txt',\n",
    "    '/kaggle/input/glove-twitter-100/glove.twitter.27B.100d.txt',\n",
    "]\n",
    "\n",
    "found = False\n",
    "for gp in glove_paths:\n",
    "    if os.path.exists(gp):\n",
    "        print('Found GloVe file at', gp)\n",
    "        embeddings_index = {}\n",
    "        with open(gp, encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "        embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "        for word, i in tok.word_index.items():\n",
    "            if i < VOCAB_SIZE:\n",
    "                vec = embeddings_index.get(word)\n",
    "                if vec is not None:\n",
    "                    embedding_matrix[i] = vec\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    print('GloVe not found in common paths. The model will use random embeddings as fallback.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94462ebe-7560-4838-8b0b-8aa0b783a3be",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# SECTION 3: Model Building and Training Process\n",
    "#------------------------------------------------------------\n",
    "\n",
    "# - Embedding (GloVe if available), Bidirectional LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7eae56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:08:14.412598Z",
     "iopub.status.busy": "2025-10-24T08:08:14.412341Z",
     "iopub.status.idle": "2025-10-24T08:08:18.171572Z",
     "shell.execute_reply": "2025-10-24T08:08:18.170951Z",
     "shell.execute_reply.started": "2025-10-24T08:08:14.412571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1761293296.139823      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1761293296.140572      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m234,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,300,545</span> (4.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,300,545\u001b[0m (4.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">300,545</span> (1.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m300,545\u001b[0m (1.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> (3.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,000,000\u001b[0m (3.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(vocab_size=VOCAB_SIZE, embed_dim=EMBEDDING_DIM, max_len=MAX_LEN, embedding_matrix=None):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    \n",
    "    if embedding_matrix is not None:\n",
    "        emb = Embedding(input_dim=vocab_size, output_dim=embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(inputs)\n",
    "    else:\n",
    "        emb = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=max_len)(inputs)\n",
    "    \n",
    "    x = Bidirectional(LSTM(128))(emb)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(embedding_matrix=embedding_matrix)\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=0.001), metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d238d-e817-4a23-864a-997544c85c94",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train with EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f21fa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:08:18.172560Z",
     "iopub.status.busy": "2025-10-24T08:08:18.172312Z",
     "iopub.status.idle": "2025-10-24T08:09:33.650311Z",
     "shell.execute_reply": "2025-10-24T08:09:33.649430Z",
     "shell.execute_reply.started": "2025-10-24T08:08:18.172542Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761293302.005545     103 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7257 - loss: 0.5366 - val_accuracy: 0.7526 - val_loss: 0.5032\n",
      "Epoch 2/6\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7688 - loss: 0.4775 - val_accuracy: 0.7677 - val_loss: 0.4779\n",
      "Epoch 3/6\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7795 - loss: 0.4624 - val_accuracy: 0.7711 - val_loss: 0.4752\n",
      "Epoch 4/6\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7871 - loss: 0.4504 - val_accuracy: 0.7800 - val_loss: 0.4638\n",
      "Epoch 5/6\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.7925 - loss: 0.4403 - val_accuracy: 0.7817 - val_loss: 0.4608\n",
      "Epoch 6/6\n",
      "\u001b[1m1120/1120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.7965 - loss: 0.4345 - val_accuracy: 0.7797 - val_loss: 0.4678\n",
      "Model saved to /kaggle/working/sentiment_lstm_refined.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, validation_split=0.1, callbacks=[es])\n",
    "\n",
    "\n",
    "# Save model\n",
    "model_path = '/kaggle/working/sentiment_lstm_refined.h5'\n",
    "model.save(model_path)\n",
    "print('Model saved to', model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea442f-fcff-45e1-8b43-6f26530b2014",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# SECTION 4: Model Evaluation on Test Set\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ce93d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:09:33.652072Z",
     "iopub.status.busy": "2025-10-24T08:09:33.651384Z",
     "iopub.status.idle": "2025-10-24T08:09:44.303573Z",
     "shell.execute_reply": "2025-10-24T08:09:44.302780Z",
     "shell.execute_reply.started": "2025-10-24T08:09:33.652049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1245/1245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.4565\n",
      "Test accuracy: 0.783665657043457\n",
      "\u001b[1m1245/1245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7707    0.8078    0.7888     19917\n",
      "           1     0.7979    0.7595    0.7782     19901\n",
      "\n",
      "    accuracy                         0.7837     39818\n",
      "   macro avg     0.7843    0.7837    0.7835     39818\n",
      "weighted avg     0.7843    0.7837    0.7835     39818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test accuracy:', acc)\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4be1bdfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:09:44.304954Z",
     "iopub.status.busy": "2025-10-24T08:09:44.304602Z",
     "iopub.status.idle": "2025-10-24T08:09:44.313365Z",
     "shell.execute_reply": "2025-10-24T08:09:44.312610Z",
     "shell.execute_reply.started": "2025-10-24T08:09:44.304925Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelWrapper ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ModelWrapper: preprocessing + inference + VADER fallback\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model, tokenizer, max_len=MAX_LEN, neutral_low=0.4, neutral_high=0.6):\n",
    "        self.model = model\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.neutral_low = neutral_low\n",
    "        self.neutral_high = neutral_high\n",
    "        self.vader = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        return clean_text(text)\n",
    "    \n",
    "    def to_sequence(self, text):\n",
    "        cleaned = self.preprocess(text)\n",
    "        seq = self.tok.texts_to_sequences([cleaned])\n",
    "        return sequence.pad_sequences(seq, maxlen=self.max_len)\n",
    "    \n",
    "    def predict(self, text):\n",
    "        x = self.to_sequence(text)\n",
    "        prob = float(self.model.predict(x)[0][0])\n",
    "        if prob > self.neutral_high:\n",
    "            return {'sentiment':'Positive', 'prob':prob}\n",
    "        elif prob < self.neutral_low:\n",
    "            return {'sentiment':'Negative', 'prob':prob}\n",
    "        else:\n",
    "            vader_score = self.vader.polarity_scores(text)['compound']\n",
    "            fallback = 'Positive' if vader_score >= 0.05 else 'Negative'\n",
    "            return {'sentiment':'Neutral_fallback', 'prob':prob, 'vader':vader_score, 'vader_sentiment':fallback}\n",
    "\n",
    "# Save wrapper artifacts:(tokenizer, model)  already saved above.\n",
    "print('ModelWrapper ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5338542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:09:44.314576Z",
     "iopub.status.busy": "2025-10-24T08:09:44.314306Z",
     "iopub.status.idle": "2025-10-24T08:09:45.116272Z",
     "shell.execute_reply": "2025-10-24T08:09:45.115565Z",
     "shell.execute_reply.started": "2025-10-24T08:09:44.314556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step\n",
      "I like candy -> {'sentiment': 'Positive', 'prob': 0.6377827525138855}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "I don't like this -> {'sentiment': 'Positive', 'prob': 0.629992663860321}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "This is the worst movie ever -> {'sentiment': 'Negative', 'prob': 0.0828750729560852}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "I love it -> {'sentiment': 'Positive', 'prob': 0.8720142841339111}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "from tensorflow.keras.models import load_model\n",
    "with open('/kaggle/working/tokenizer.pickle', 'rb') as handle:\n",
    "    tok2 = pickle.load(handle)\n",
    "\n",
    "model2 = load_model('/kaggle/working/sentiment_lstm_refined.h5')\n",
    "wrapper = ModelWrapper(model2, tok2)\n",
    "\n",
    "tests = [\"I like candy\", \"I don't like this\", \"This is the worst movie ever\", \"I love it\"]\n",
    "for t in tests:\n",
    "    print(t, \"->\", wrapper.predict(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984143e-002e-430f-b6ea-7bd96f398c85",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# SECTION 5: User Input Sentiment Prediction\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c010e20-f2ed-4db7-a32a-c54068ce9098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T08:13:10.527560Z",
     "iopub.status.busy": "2025-10-24T08:13:10.527198Z",
     "iopub.status.idle": "2025-10-24T08:21:57.702194Z",
     "shell.execute_reply": "2025-10-24T08:21:57.701407Z",
     "shell.execute_reply.started": "2025-10-24T08:13:10.527521Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis (type 'exit' to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  theu are sweet couple\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
      "\n",
      "Input: theu are sweet couple\n",
      "Predicted Sentiment: Positive\n",
      "Confidence: 0.79\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  That's not bad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\n",
      "Input: That's not bad\n",
      "Predicted Sentiment: Negative\n",
      "Confidence: 0.24\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  you are briliant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "Input: you are briliant\n",
      "Predicted Sentiment: Neutral_fallback\n",
      "Confidence: 0.55\n",
      "VADER Fallback → Negative (score=0.000)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  you wrong\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "Input: you wrong\n",
      "Predicted Sentiment: Negative\n",
      "Confidence: 0.23\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  you are super, I admire\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "Input: you are super, I admire\n",
      "Predicted Sentiment: Positive\n",
      "Confidence: 0.99\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "with open('/kaggle/working/tokenizer.pickle', 'rb') as handle:\n",
    "    tok = pickle.load(handle)\n",
    "\n",
    "model = load_model('/kaggle/working/sentiment_lstm_refined.h5')\n",
    "\n",
    "wrapper = ModelWrapper(model, tok)\n",
    "\n",
    "print(\"Sentiment Analysis (type 'exit' to quit)\")\n",
    "while True:\n",
    "    user_input = input(\"Enter a sentence: \").strip()\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    result = wrapper.predict(user_input)\n",
    "    \n",
    "    print(f\"\\nInput: {user_input}\")\n",
    "    print(f\"Predicted Sentiment: {result['sentiment']}\")\n",
    "    print(f\"Confidence: {result['prob']:.2f}\")\n",
    "    if 'vader' in result:\n",
    "        print(f\"VADER Fallback → {result['vader_sentiment']} (score={result['vader']:.3f})\")\n",
    "    print(\"-\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8561340,
     "sourceId": 13484888,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8561395,
     "sourceId": 13484965,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
